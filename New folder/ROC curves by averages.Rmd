---
title: "ROC Curves on average"
author: "Hana Lee"
date: "April 20, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#### Code for prediction by methods
paired.test \%>\% 
  mutate(matching.optimal = optimal.uni.w(X1, X2, G, 
                                          mu.hat, sigma.hat, prior.p,
                                          weight.DS.error = WEIGTS))
                                          
predict(lda(X, Y), X.test, prior = PRIOR_PROBABILITY)$class

predict(qda(X, Y), X.test, prior = PRIOR_PROBABILITY)$class

randomForest(x = as.matrix(paired.train\$diff.X), 
             y = as.factor(paired.train\$group.matching),
             xtest = as.matrix(paired.test$diff.X),
             ntree = n.trees,
             cutoff = PRIOR_PROBABILITY)\$test\$predicted)

#### Note
- (0, 1) and (1, 0) are excluded from cutoffs since they are not compatible with `randomForest`.

- Different priors make different posterior probabities, so it looks different from random forest method using cutoffs.

```{r, message = FALSE, echo = FALSE, warning = FALSE}
  library(tidyverse)
  library(randomForest)
  library(MASS)
#  library(mda)

optimal.uni.w <- function(x1, x2, G, mu.vec, sigma.vec, prior.p, weight.DS.error){
# Here, G is the number of group
# Independence assumed among observations
# optimal matching rule with G groups under normal distributions
# mu is an G dimensional vector for group means
# prior probabilities are assumed the same
# As weight.DS.error (a vector) increases, sensitivity increases but specificity decreases
  if(sum(weight.DS.error <0 | weight.DS.error >1) != 0) stop("Weights must be in [0, 1]")
  
  between.group = 0
  for (j1 in 1 : G){
    for (j2 in 1 : G){
      if (j1 != j2){
        temp = dnorm(x1, mu.vec[j1],sigma.vec[j1]) * dnorm(x2, mu.vec[j2], sigma.vec[j2]) * prior.p[j1] * prior.p[j2] * (1 - weight.DS.error)
        between.group = between.group + temp #LHS term w/o p's in the equation (6)
      }
    }
  }
  within.group = 0
  for (j in 1 : G){
    temp = dnorm(x1, mu.vec[j], sigma.vec[j]) * dnorm(x2, mu.vec[j], sigma.vec[j]) * (prior.p[j])^2 * weight.DS.error
    within.group = within.group + temp #RHS term w/o p's in the equation (6)
  }
  return(1 * (between.group <= within.group)) #1 if (x1, x2) belongs to T_m in the equation (6)
}

paring.uni <- function(no.of.obs, data.X , data.Y){
  # data.X contains info of response values 
  # data.Y contains info of groups
  id.set <- t(combn(no.of.obs,2))
  
  id1 <- as.data.frame(id.set[,1]) %>%
    rename(id = `id.set[, 1]`)
  
  id2 <- as.data.frame(id.set[,2]) %>%
    rename(id = `id.set[, 2]`)
  
  XY.with.id <- as.data.frame(cbind(1:no.of.obs, data.X, data.Y)); colnames(XY.with.id) <- c("id", "X", "Y")
  XY.with.id1 <- left_join(id1, XY.with.id, by = "id"); colnames(XY.with.id1) <- c("id1", "X1", "Y1")
  XY.with.id2 <- left_join(id2, XY.with.id, by = "id"); colnames(XY.with.id2) <- c("id2", "X2", "Y2")
  
  paired <- cbind(XY.with.id1, XY.with.id2) %>%
    mutate(diff.X = X1 - X2,
           group.matching = if_else(Y1==Y2, 1, 0))
  
  return(paired)
}

ROC.uni <- function(B, N=1, G, mu.vec, sigma.vec, prior.p, n, n.test, 
                    weight.DS.error = seq(0, 1, by = 0.01), n.trees, result.name){
  start.t <- Sys.time()
  
  if(length(mu.vec)!=G) stop("Please match the dimension of mu, and the number of groups")
  if(length(sigma.vec)!=G) stop("Please match the dimension of mu, and the number of groups")
  
  if(N>1) stop("Univariate (N=1) case only; for multivariate case, use 'compare.multi'")
  
  if(G!=length(prior.p)) stop("Please match the number of group and prior.p dimension")
  
  tmp <- c()
  tmp2 <- c()
  for (g in 1:G){
    tmp <- c(tmp, is.integer(n*prior.p[g]))
    tmp2 <- c(tmp2, is.integer(n.test*prior.p[g]))
  }
  if(sum(tmp, tmp2)!=0) stop("Please make sure # of obs from each group to be integers")
  
  if(is.null(weight.DS.error) == FALSE & (mean(is.numeric(weight.DS.error)) != 1 | is.vector(weight.DS.error) == FALSE)){
    stop("weight.DS.error must be either NULL or a numeric vector of weights in [0, 1]")}
  if(is.null(weight.DS.error) == FALSE & sum(weight.DS.error <0 | weight.DS.error >1) != 0){
    stop("weight.DS.error must be weights in [0, 1] when it's not NULL")}  
####    
no.obs.by.groups.train <- n*prior.p
no.obs.by.groups.test <- n.test*prior.p

Y <- as.factor(rep(1:G, times = no.obs.by.groups.train))
Y.test <- as.factor(rep(1:G, times = no.obs.by.groups.test))
####

accuracy.optimal <- c()
sensitivity.optimal <- c()
specificity.optimal <- c()

accuracy.rf <- c()
sensitivity.rf <- c()
specificity.rf <- c()

accuracy.lda <- c()
sensitivity.lda <- c()
specificity.lda <- c()

accuracy.qda <- c()
sensitivity.qda <- c()
specificity.qda <- c()

times.RF <- c()
times.optimal <- c()
times.lda <- c()
times.qda <- c()
for(repetition in 1:B){
  ##### Genarating data and estimating mean and variance for optimal rule#####
  X <- c()
  X.test <- c()
  mu.hat <- c()
  var.hat <- c()
  for(g in 1:G){
    X.g <- rnorm(no.obs.by.groups.train[g], mu.vec[g], sigma.vec[g])
    X.g.test <- rnorm(no.obs.by.groups.test[g], mu.vec[g], sigma.vec[g])
    
    X <- c(X, X.g)
    X.test <- c(X.test, X.g.test)
    
    mu.hat <- c(mu.hat, mean(X.g)) #mu.hat is G by 1 vector
    var.hat <- c(var.hat, var(X.g))
  }
  X <- as.matrix(X)
  X.test <- as.matrix(X.test)  

  # Variance estimation for optimal rule 
  if((max(sigma.vec) - min(sigma.vec)) ==0){
    pooled.sd <- sqrt(sum(var.hat * (no.obs.by.groups.train - 1))/(n - G))
    sigma.hat <- rep(pooled.sd, G)
  }else{sigma.hat <- sqrt(var.hat)}
  ##############################################################################
  
  
  ##### Pairing test data, and computing feature difference #####
  paired.train <- paring.uni(n, X, Y)
  ###############################################################
  
  
  ##### Pairing test data, and computing feature difference #####
  paired.test <- paring.uni(n.test, X.test, Y.test)  
  ############################################################### 
  
  

  ##### Matching on test set by Random Forest #####
start.RF <- Sys.time()
tol <- 0.00001
cutoffs <- (combn(21,1) - 1 )*0.05
cutoffs[1,1] <- tol; cutoffs[1, ncol(cutoffs)] <- 1-tol
cutoffs <- rbind(cutoffs, 1) - rbind(0, cutoffs)
predict.rf.w <- 1:ncol(cutoffs) %>% 
  map(~cutoffs[, .x]) %>%
  map(~cbind.data.frame(group.matching = paired.test$group.matching,
                        matching.rf = as.numeric(as.character(randomForest(x = as.matrix(paired.train$diff.X), 
                       y = as.factor(paired.train$group.matching),
                       xtest = as.matrix(paired.test$diff.X),
                       ntree = n.trees,
                       cutoff = .x)$test$predicted)))) 

accuracy.rf.w <- predict.rf.w %>% 
  map(~.x %>%
        summarise(mean(matching.rf == group.matching))) %>%
  unlist(use.names = FALSE)
accuracy.rf <- cbind(accuracy.rf, accuracy.rf.w)

sensitivity.rf.w <- predict.rf.w %>% 
  map(~.x %>%
        filter(group.matching == 1) %>%
  summarise(mean(matching.rf == group.matching))) %>%
  unlist(use.names = FALSE)
sensitivity.rf <- cbind(sensitivity.rf, sensitivity.rf.w)

specificity.rf.w <- predict.rf.w %>% 
  map(~.x %>%
        filter(group.matching == 0) %>%
  summarise(mean(matching.rf == group.matching))) %>%
  unlist(use.names = FALSE)
specificity.rf <- cbind(specificity.rf, specificity.rf.w)
end.RF <- Sys.time()
  #################################################
  

  start.lda <- Sys.time()
  ##### Prediction and matching on test set by LDA #####
  cutoffs <- (combn(21,(G-1)) - 1 )*0.05
#  for(a in 1:nrow(cutoffs)){
#    for(b in 1:ncol(cutoffs)){
#      if(cutoffs[a, b] == 0){cutoffs[a, b] <- tol}
#      if(cutoffs[a, b] == 1){cutoffs[a, b] <- 1-tol}
#      }}
  cutoffs <- rbind(cutoffs, 1) - rbind(0, cutoffs)
  lda.qda.dat <- 1:ncol(cutoffs) %>% map(~paired.test)
  fit.lda <- lda(X, Y)
  lda.prediction <- 1:ncol(cutoffs) %>% 
  map(~cutoffs[, .x]) %>%
  map(~cbind.data.frame(matching.lda1 = as.numeric(predict(fit.lda,
                                                           X.test,
                                                           prior = .x)$class),
                        id1 = 1:n.test)) 
  lda.matching1 <- lda.qda.dat %>% 
    map2(lda.prediction,
         ~left_join(.x, .y, by = "id1"))
                       
  predict.lda.w <- lda.prediction %>% map(~rename(.x, 
                                                 matching.lda2 = matching.lda1,
                                                 id2 = id1)) %>% 
    map2(lda.matching1,
         ~left_join(.y, .x, by = "id2")) %>%
    map(~mutate(.x,
                matching.lda = as.numeric(matching.lda1 == matching.lda2)))
  
  accuracy.lda.w <- predict.lda.w %>% 
  map(~.x %>%
        summarise(mean(matching.lda == group.matching))) %>%
  unlist(use.names = FALSE)
accuracy.lda <- cbind(accuracy.lda, accuracy.lda.w)

sensitivity.lda.w <- predict.lda.w %>% 
  map(~.x %>%
        filter(group.matching == 1) %>%
  summarise(mean(matching.lda == group.matching))) %>%
  unlist(use.names = FALSE)
sensitivity.lda <- cbind(sensitivity.lda, sensitivity.lda.w)

specificity.lda.w <- predict.lda.w %>% 
  map(~.x %>%
        filter(group.matching == 0) %>%
  summarise(mean(matching.lda == group.matching))) %>%
  unlist(use.names = FALSE)
specificity.lda <- cbind(specificity.lda, specificity.lda.w)
end.lda <- Sys.time()
  ######################################################
  
  




  start.qda <- Sys.time()
  ##### Prediction and matching on test set by qda #####
  lda.qda.dat <- 1:ncol(cutoffs) %>% map(~paired.test)
  
  fit.qda <- qda(X, Y)
  qda.prediction <- 1:ncol(cutoffs) %>% 
  map(~cutoffs[, .x]) %>%
  map(~cbind.data.frame(matching.qda1 = as.numeric(predict(fit.qda,
                                                           X.test,
                                                           prior = .x)$class),
                        id1 = 1:n.test)) 
  qda.matching1 <- lda.qda.dat %>% 
    map2(qda.prediction,
         ~left_join(.x, .y, by = "id1"))
                       
  predict.qda.w <- qda.prediction %>% map(~rename(.x, 
                                                 matching.qda2 = matching.qda1,
                                                 id2 = id1)) %>% 
    map2(qda.matching1,
         ~left_join(.y, .x, by = "id2")) %>%
    map(~mutate(.x,
                matching.qda = as.numeric(matching.qda1 == matching.qda2)))
  
  accuracy.qda.w <- predict.qda.w %>% 
  map(~.x %>%
        summarise(mean(matching.qda == group.matching))) %>%
  unlist(use.names = FALSE)
accuracy.qda <- cbind(accuracy.qda, accuracy.qda.w)

sensitivity.qda.w <- predict.qda.w %>% 
  map(~.x %>%
        filter(group.matching == 1) %>%
  summarise(mean(matching.qda == group.matching))) %>%
  unlist(use.names = FALSE)
sensitivity.qda <- cbind(sensitivity.qda, sensitivity.qda.w)

specificity.qda.w <- predict.qda.w %>% 
  map(~.x %>%
        filter(group.matching == 0) %>%
  summarise(mean(matching.qda == group.matching))) %>%
  unlist(use.names = FALSE)
specificity.qda <- cbind(specificity.qda, specificity.qda.w)
end.qda <- Sys.time()
  ######################################################

  ##### Prediction and matching on test set by QDA #####
  #fit.qda <- qda(X, Y); predict.qda <- as.numeric(predict(fit.qda, X.test)$class)
  
  #paired.test$matching.qda <- as.numeric(predict.qda[paired.test$id1] == predict.qda[paired.test$id2])
  #fit.mda = mda(Y~X); predict.mda = predict(fit.mda, X.test)
  #fit.fda = fda(Y~X); predict.fda = predict(fit.fda, X.test)
  ######################################################
  
  
  ##### Matching and predicon test set by Optimal Rule with various weights #####
  start.optimal <- Sys.time()
  matching.result.w <- weight.DS.error %>% 
    map(~(mutate(paired.test,
                 matching.optimal = optimal.uni.w(X1, X2, G, 
                                                  mu.hat, sigma.hat, prior.p,
                                                  weight.DS.error = .x))))
  
  accuracy.optimal.w <- matching.result.w %>%
    map(~(summarise(.x, 
                    Optimal = mean(.x$matching.optimal == .x$group.matching)))) %>%
    unlist(use.names = FALSE)
  accuracy.optimal <- cbind(accuracy.optimal, accuracy.optimal.w)

  
  sensitivity.optimal.w <- matching.result.w %>%
    map(~(filter(.x, group.matching == 1) %>% 
            summarise(Optimal = mean(matching.optimal == group.matching)))) %>%
    unlist(use.names = FALSE)
  sensitivity.optimal <- cbind(sensitivity.optimal, sensitivity.optimal.w)
  
  specificity.optimal.w <- matching.result.w %>%
    map(~(filter(.x, group.matching == 0) %>% 
            summarise(Optimal = mean(matching.optimal == group.matching)))) %>%
    unlist(use.names = FALSE)
  specificity.optimal <- cbind(specificity.optimal, specificity.optimal.w)
  end.optimal <- Sys.time()
  
  times.RF <- c(times.RF, difftime(end.RF, start.RF, units = "mins"))
  times.optimal <- c(times.optimal, difftime(end.optimal, start.optimal, units = "mins"))
  times.lda <- c(times.lda, difftime(end.lda, start.lda, units = "mins"))
  times.qda <- c(times.qda, difftime(end.qda, start.qda, units = "mins"))
} 

sensitivity.optimal.avg <- apply(sensitivity.optimal, 1, mean)
specificity.optimal.avg <- apply(specificity.optimal, 1, mean)
sens.spec.avg.optimal <- cbind.data.frame(sensitivity = sensitivity.optimal.avg, 
                                          specificity = specificity.optimal.avg,
                                          method = "Optimal Rule")

sensitivity.rf.avg <- apply(sensitivity.rf, 1, mean)
specificity.rf.avg <- apply(specificity.rf, 1, mean)
sens.spec.avg.rf <- cbind.data.frame(sensitivity = sensitivity.rf.avg, 
                                 specificity = specificity.rf.avg,
                                          method = "RF")

sensitivity.lda.avg <- apply(sensitivity.lda, 1, mean)
specificity.lda.avg <- apply(specificity.lda, 1, mean)
sens.spec.avg.lda <- cbind.data.frame(sensitivity = sensitivity.lda.avg, 
                                  specificity = specificity.lda.avg,
                                          method = "LDA")

sensitivity.qda.avg <- apply(sensitivity.qda, 1, mean)
specificity.qda.avg <- apply(specificity.qda, 1, mean)
sens.spec.avg.qda <- cbind.data.frame(sensitivity = sensitivity.qda.avg, 
                                  specificity = specificity.qda.avg,
                                          method = "QDA")

sens.spec.avg <- rbind(sens.spec.avg.optimal,
                       sens.spec.avg.rf,
                       sens.spec.avg.lda,
                       sens.spec.avg.qda)
end.t <- Sys.time()

ggsave(paste(result.name, ".png", sep = ""), 
       sens.spec.avg %>% 
  ggplot(aes(x = 1 - specificity, 
             y = sensitivity,
             colour = factor(method))) +
  geom_line() +
  labs(color = "Method") +
  theme(legend.position = c(0.85, 0.15)) +
  ggtitle("ROC with sensitivity and specificity 
          avaraged by weights (cutoffs)"))

yaml::write_yaml(list(`Group Means` = mu.vec,
                      `Group Variances` = sigma.vec^2,
                      `Total time (minutes)` = difftime(end.t, start.t, units = "mins"),
                      `The number of repetitions` = B,
                      `Average minutes for Optimal Rule` = mean(times.optimal),
                      `Average minutes for LDA` = mean(times.lda),
                      `Average minutes for QDA` = mean(times.qda),
                      `Average minutes for RF` = mean(times.RF)), 
                 paste(result.name, ".yaml", sep = ""))
yaml::write_yaml(list(sensitivity.optimal, 
                      specificity.optimal,
                      sensitivity.lda,
                      specificity.lda,
                      sensitivity.qda,
                      specificity.qda,
                      sensitivity.rf,
                      specificity.rf),
                 paste(result.name, "_data.yaml", sep = ""))
}

f.res.dat <- function(res){
  res.dat <- yaml::yaml.load_file(paste(res, "_data.yaml", sep = ""))

  for(k in 1:8){
    
  if(k <= 2){
    res.dat[[k]] <- matrix(res.dat[[k]], length(res.dat[[k]])/100, 100)
  }else{res.dat[[k]] <- matrix(res.dat[[k]], length(res.dat[[k]])/100, 100)
  }}
  
  sens.optimal <- cbind.data.frame(weights = 1:nrow(res.dat[[1]]), res.dat[[1]]) %>% 
  gather(key = "repetition", value = "sensitivity", -weights) %>% 
  mutate(repetition = as.numeric(repetition)) %>%
  arrange(weights, repetition)

spec.optimal <- cbind.data.frame(weights = 1:nrow(res.dat[[2]]), res.dat[[2]]) %>% 
  gather(key = "repetition", value = "specificity", -weights) %>% 
  mutate(repetition = as.numeric(repetition)) %>%
  arrange(weights, repetition)


sens.lda <- cbind.data.frame(weights = 1:nrow(res.dat[[3]]), res.dat[[3]]) %>% 
  gather(key = "repetition", value = "sensitivity", -weights) %>% 
  mutate(repetition = as.numeric(repetition)) %>%
  arrange(weights, repetition)

spec.lda <- cbind.data.frame(weights = 1:nrow(res.dat[[4]]), res.dat[[4]]) %>% 
  gather(key = "repetition", value = "specificity", -weights) %>% 
  mutate(repetition = as.numeric(repetition)) %>%
  arrange(weights, repetition)

sens.qda <- cbind.data.frame(weights = 1:nrow(res.dat[[5]]), res.dat[[5]]) %>% 
  gather(key = "repetition", value = "sensitivity", -weights) %>% 
  mutate(repetition = as.numeric(repetition)) %>%
  arrange(weights, repetition)

spec.qda <- cbind.data.frame(weights = 1:nrow(res.dat[[6]]), res.dat[[6]]) %>% 
  gather(key = "repetition", value = "specificity", -weights) %>% 
  mutate(repetition = as.numeric(repetition)) %>%
  arrange(weights, repetition)

sens.rf <- cbind.data.frame(weights = 1:nrow(res.dat[[7]]), res.dat[[7]]) %>% 
  gather(key = "repetition", value = "sensitivity", -weights) %>% 
  mutate(repetition = as.numeric(repetition)) %>%
  arrange(weights, repetition)

spec.rf <- cbind.data.frame(weights = 1:nrow(res.dat[[8]]), res.dat[[8]]) %>% 
  gather(key = "repetition", value = "specificity", -weights) %>% 
  mutate(repetition = as.numeric(repetition)) %>%
  arrange(weights, repetition)

sens.spec.optimal <- full_join(sens.optimal, spec.optimal, by = c("weights", "repetition"))
sens.spec.lda <- full_join(sens.lda, spec.lda, by = c("weights", "repetition"))
sens.spec.qda <- full_join(sens.qda, spec.qda, by = c("weights", "repetition"))
sens.spec.rf <- full_join(sens.rf, spec.rf, by = c("weights", "repetition"))

return(list(optimal = cbind.data.frame(sens.spec.optimal, method = "optimal"),
            lda = cbind.data.frame(sens.spec.lda, method = "lda"),
            qda = cbind.data.frame(sens.spec.qda, method = "qda"),
            rf = cbind.data.frame(sens.spec.rf, method = "rf")))

  }

f.res.plot <- function(res, weights = FALSE){
  if(is.logical(weights) == FALSE){stop("Weights must be a logical value.")}
  if(weights == FALSE){
  return(f.res.dat(res) %>% 
  map(~.x %>% 
        group_by(method, specificity) %>% 
        summarise(avg.sens = mean(sensitivity)) %>%
        ungroup()) %>%
  rlist::list.rbind() %>%
    ggplot(aes(x = 1 - specificity, 
               y = avg.sens, 
               colour = method)) +
    geom_line() + 
    ggtitle("ROC with average sensitivity by specificity regardless of weights"))
  }else{
    return(f.res.dat(res) %>% 
  map(~.x %>% 
        group_by(method, weights, specificity) %>% 
        summarise(avg.sens = mean(sensitivity)) %>%
        ungroup()) %>%
  rlist::list.rbind() %>%
    ggplot(aes(x = 1 - specificity, 
               y = avg.sens, 
               colour = method)) +
    geom_line() + 
    ggtitle("ROC with average sensitivity by weights and specificity"))
  }}
```


```{r, message = FALSE, eval = FALSE, echo = FALSE, warning = FALSE}
ROC.uni(B = 100, N = 1, G = 2, 
                            mu.vec = c(1, 1.5),
                            sigma.vec = c(1, 5), 
                            prior.p = c(1,1)/2, 
                            n = 100, n.test = 20, n.trees = 100,
                    result.name = "uni.Sg.2") 
#yaml::yaml.load_file("uni.Sg.2.yaml")
#uni.Sg.2.dat <- f.res.dat("uni.Sg.2")
#magick::image_scale(magick::image_read("uni.Sg.2.png"), "1200")

ROC.uni(B = 100, N = 1, G = 3, 
                            mu.vec = c(1, 1.5, 4),
                            sigma.vec = c(1, 2, 3), 
                            prior.p = c(1,1,1)/3, 
                            n = 150, n.test = 30, n.trees = 100,
                    result.name = "uni.Sg.3")

ROC.uni(B = 100, N = 1, G = 5, 
                            mu.vec = c(-1, 1, 4, 7, 10),
                            sigma.vec = c(1, 1.5, 2, 2.5, 3), 
                            prior.p = c(1,1,1,1,1)/5, 
                            n = 250, n.test = 50, n.trees = 100,
                    result.name = "uni.Sg.5")

#ROC.uni(B = 100, N = 1, G = 10, 
 #                           mu.vec = c(c(1, 0, -1, 0.5, 2), c(1, 0, -1, 0.5, 2) -10),
  #                          sigma.vec = c(1:5, 1:5), 
   #                         prior.p = rep(1, 10)/10, 
    #                        n = 500, n.test = 100, n.trees = 100,
     #               result.name = "uni.Sg.10") #Error: cannot allocate vector of size 39 Kb

ROC.uni(B = 100, N = 1, G = 2, 
                            mu.vec = c(1, 3),
                            sigma.vec = rep(2, 2), 
                            prior.p = c(1,1)/2, 
                            n = 100, n.test = 20, n.trees = 100,
                    result.name = "uni.Sp.2") 

ROC.uni(B = 100, N = 1, G = 3, 
                            mu.vec = c(1, 1.5, 2),
                            sigma.vec = rep(0.5, 3), 
                            prior.p = c(1,1,1)/3, 
                            n = 150, n.test = 30, n.trees = 100,
                    result.name = "uni.Sp.3")

ROC.uni(B = 100, N = 1, G = 5, 
                            mu.vec = c(1, 0, -1, 0.5, 2),
                            sigma.vec = rep(1, 5), 
                            prior.p = c(1,1,1,1,1)/5, 
                            n = 250, n.test = 50, n.trees = 100,
                    result.name = "uni.Sp.5")

#ROC.uni(B = 100, N = 1, G = 10, 
 #                           mu.vec = c(c(1, 0, -1, 0.5, 2), c(1, 0, -1, 0.5, 2) -10),
  #                          sigma.vec = rep(4, 10), 
   #                         prior.p = rep(1, 10)/10, 
    #                        n = 500, n.test = 100, n.trees = 100,
     #               result.name = "uni.Sp.10")



```

```{r, message = FALSE, echo = FALSE, warning = FALSE, fig.align = "center"}

yaml::yaml.load_file("uni.Sg.2.yaml")
f.res.dat("uni.Sg.2") %>% rlist::list.rbind() %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, colour = method)) + 
           geom_point() + facet_wrap(vars(method))
magick::image_scale(magick::image_read("uni.Sg.2.png"), "1200")
f.res.plot("uni.Sg.2", weights = F)
f.res.plot("uni.Sg.2", weights = T)



yaml::yaml.load_file("uni.Sg.3.yaml")
f.res.dat("uni.Sg.3") %>% rlist::list.rbind() %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, colour = method)) + 
           geom_point() + facet_wrap(vars(method))
magick::image_scale(magick::image_read("uni.Sg.3.png"), "1200")
f.res.plot("uni.Sg.3", weights = F)
f.res.plot("uni.Sg.3", weights = T)




yaml::yaml.load_file("uni.Sg.5.yaml")
f.res.dat("uni.Sg.5") %>% rlist::list.rbind() %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, colour = method)) + 
           geom_point() + facet_wrap(vars(method))
magick::image_scale(magick::image_read("uni.Sg.5.png"), "1200")
f.res.plot("uni.Sg.5", weights = F)
f.res.plot("uni.Sg.5", weights = T)






yaml::yaml.load_file("uni.Sp.2.yaml")
f.res.dat("uni.Sp.2") %>% rlist::list.rbind() %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, colour = method)) + 
           geom_point() + facet_wrap(vars(method))
magick::image_scale(magick::image_read("uni.Sp.2.png"), "1200")
f.res.plot("uni.Sp.2", weights = F)
f.res.plot("uni.Sp.2", weights = T)




yaml::yaml.load_file("uni.Sp.3.yaml")
f.res.dat("uni.Sp.3") %>% rlist::list.rbind() %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, colour = method)) + 
           geom_point() + facet_wrap(vars(method))
magick::image_scale(magick::image_read("uni.Sp.3.png"), "1200")
f.res.plot("uni.Sp.3", weights = F)
f.res.plot("uni.Sp.3", weights = T)


yaml::yaml.load_file("uni.Sp.5.yaml")
f.res.dat("uni.Sp.5") %>% rlist::list.rbind() %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, colour = method)) + 
           geom_point() + facet_wrap(vars(method))
magick::image_scale(magick::image_read("uni.Sp.5.png"), "1200")
f.res.plot("uni.Sp.5", weights = F)
f.res.plot("uni.Sp.5", weights = T)
```






```{r, echo = FALSE, eval = FALSE, message = FALSE, warning = FALSE}
 #### x's ~ iid mixed multivariate normal with G-group cases (Generalization)
  library(tidyverse)
  library(randomForest)
  library(MASS)

# Here, m is the number of group
# Independence assumed among observations
# optimal matching rule with m groups under normal distributions
# x1, x2 are N by 1 vectors  
# mu is an N by m matrix for group means
# sigma is N by N matrix which is common for f_1, f_2, and f_3 where f = p_1*f_1 + p_2*f_2 + p_3*f_3
# prior probabilities are assumed the same
optimal.multi.w = function(x1.vec, x2.vec, G, mu.vec.list, covariance.matrix.list, prior.p, weight.DS.error){
  between.group = 0
  for (j1 in 1 : G){
    for (j2 in 1 : G){
      if (j1 != j2){
        temp = mvtnorm::dmvnorm(x1.vec, 
                                mu.vec.list[[j1]], 
                                covariance.matrix.list[[j1]]) * mvtnorm::dmvnorm(x2.vec, 
                                                                                 mu.vec.list[[j2]], 
                                                                                 covariance.matrix.list[[j2]]) * prior.p[j1] * prior.p[j2] * (1 - weight.DS.error)
        between.group = between.group + temp #LHS term w/o p's in the equation (6)
      }
    }
  }
  within.group = 0
  for (j in 1 : G){
    temp = mvtnorm::dmvnorm(x1.vec, 
                            mu.vec.list[[j]], 
                            covariance.matrix.list[[j]]) * mvtnorm::dmvnorm(x2.vec,
                                                                            mu.vec.list[[j]], 
                                                                            covariance.matrix.list[[j]]) * (prior.p[j])^2 * weight.DS.error
    within.group = within.group + temp #RHS term w/o p's in the equation (6)
  }
  return(1 * (between.group <= within.group)) #1 if (x1, x2) belongs to T_m in the equation (6)
}


paring.multi <- function(no.of.obs, data.X , data.Y){
  # data.X contains info of response values 
  # data.Y contains info of groups
  id.set <- t(combn(no.of.obs,2))
  
  id1 <- as.data.frame(id.set[,1]) %>%
    rename(id = `id.set[, 1]`)
  
  id2 <- as.data.frame(id.set[,2]) %>%
    rename(id = `id.set[, 2]`)
  
  dim.data.X <- ncol(data.X)
  XY.with.id <- as.data.frame(cbind(1:no.of.obs, data.X, data.Y))
  colnames(XY.with.id) <- c("id", paste("X.coord", 1:dim.data.X, sep=""), "Y")
  XY.with.id1 <- left_join(id1, XY.with.id, by = "id")
  colnames(XY.with.id1) <- c("id1", paste("X.coord", 1:dim.data.X, "_1", sep=""), "Y1")
  XY.with.id2 <- left_join(id2, XY.with.id, by = "id")
  colnames(XY.with.id2) <- c("id2", paste("X.coord", 1:dim.data.X, "_2", sep=""), "Y2")
  
  diff.X <- XY.with.id1[ , paste("X.coord", 1:dim.data.X, "_1", sep="")] -
    XY.with.id2[ , paste("X.coord", 1:dim.data.X, "_2", sep="")]
  colnames(diff.X) <- paste("diff.X.coord", 1:dim.data.X, sep = "")
    
  paired <- cbind(XY.with.id1, 
                  XY.with.id2, 
                  diff.X) %>%
    mutate(group.matching = if_else(Y1==Y2, 1, 0))
  
  return(paired)
}

#The same function in "Simulation.Rmd" except that QDA is added
ROC.multi <- function(B = 1, N, G, mu.vec.list, covariance.matrix.list, 
                            prior.p, n, n.test, weight.DS.error = seq(0, 1, by = 0.01), n.trees){



  cat("MULTIVARIATE CASE \n \n")
  
  cat("Mean Parameter Vectors by groups: \n")
  print(mu.vec.list)

  cat("Cavariance Parameter Matrices by groups: \n")
  print(covariance.matrix.list)

  
  if(N==1) stop("Multivariate (N>1) case only")
  #if(N!=nrow(common.sigma)) stop("Please match the dimensions of an obs x and common.sigma")
  
  #if(G!=length(prior.p)) stop("Please match the number of group and prior.p dimension")
  
  tmp <- c()
  tmp2 <- c()
  for (k in 1:G){
    tmp <- c(tmp, is.integer(n*prior.p[k]))
    tmp2 <- c(tmp2, is.integer(n.test*prior.p[k]))
  }
  if(sum(tmp, tmp2)!=0) stop("Please make sure # of obs from each group to be integers")

####
tmp1 <- covariance.matrix.list; tmp1[[1]] <- NULL
tmp2 <- covariance.matrix.list; tmp2[[G]] <- NULL
if(sum(Reduce('+', map2(tmp1, tmp2, ~abs(.x-.y)))) == 0){
  common.variance = TRUE}else{common.variance = FALSE} #common.variance = TRUE if all group covariances are the same.
  

no.obs.by.groups.train <- n*prior.p
no.obs.by.groups.test <- n.test*prior.p

Y <- as.factor(rep(1:G, times = no.obs.by.groups.train))
Y.test <- as.factor(rep(1:G, times = no.obs.by.groups.test))
####

  ##### Genarating data and estimating mean and variance for optimal rule#####
  X <- c()
  X.test <- c()
  mu.hat <- list()
  var.hat <- list()
  for(g in 1:G){
    X.g <- mvtnorm::rmvnorm(no.obs.by.groups.train[g], 
                            mu.vec.list[[g]], 
                            covariance.matrix.list[[g]])
    X.g.test <- mvtnorm::rmvnorm(no.obs.by.groups.test[g], 
                                 mu.vec.list[[g]], 
                                 covariance.matrix.list[[g]])
    
    X <- as.matrix(rbind(X, X.g))
    X.test <- as.matrix(rbind(X.test, X.g.test))
    
    mu.hat[[g]] <- apply(X.g, 2, mean) #mu.hat is a list of G N*1 vectors
    var.hat[[g]] <- var(X.g)
  }
  
    # Variance estimation for optimal rule 
  if(common.variance == TRUE){
    pooled.covariance <- Reduce('+', map2(var.hat, no.obs.by.groups.train, ~ .x * (.y -1)))/(n - G)
    covariance.hat <- 1:G %>% map(~pooled.covariance)
  }else{covariance.hat <- var.hat}
  ##############################################################################

  
  ##### Pairing test data, and computing feature difference #####
  paired.train <- paring.multi(n, X, Y)
  ###############################################################
  
  
  ##### Pairing test data, and computing feature difference #####
  paired.test <- paring.multi(n.test, X.test, Y.test)  
  ############################################################### 
  
  
  ##### Matching on test set by Random Forest #####
  predict.rf <- randomForest(x = as.matrix(paired.train[ , paste("diff.X.coord", 1:N, sep = "")]), 
                             y = as.factor(paired.train$group.matching), 
                             xtest = as.matrix(paired.test[ , paste("diff.X.coord", 1:N, sep = "")]),
                             ntree = n.trees)
  roc.rf <- pROC::roc(as.factor(paired.test$group.matching), 
                      predict.rf$test$votes[,2])
  sens.spec.rf <- cbind.data.frame(roc.rf$sensitivities,
                                   roc.rf$specificities)
  #################################################

  
  ##### Prediction and matching on test set by LDA #####
  #fit.lda <- lda(X, Y); predict.lda <- as.numeric(predict(fit.lda, X.test)$class)
  
  #paired.test$matching.lda <- as.numeric(predict.lda[paired.test$id1] == predict.lda[paired.test$id2])
  ######################################################
  
  
  ##### Prediction and matching on test set by QDA #####
  #fit.qda <- qda(X, Y); predict.qda <- as.numeric(predict(fit.qda, X.test)$class)
  
  #paired.test$matching.qda <- as.numeric(predict.qda[paired.test$id1] == predict.qda[paired.test$id2])
  #fit.mda = mda(Y~X); predict.mda = predict(fit.mda, X.test)
  #fit.fda = fda(Y~X); predict.fda = predict(fit.fda, X.test)
  ######################################################

  WEIGHT <- 0.5
  X1.coordinates <- paste("c(", paste0("X.coord", 1:N, "_1", collapse = ","), ")", sep = "")
  X2.coordinates <- paste("c(", paste0("X.coord", 1:N, "_2", collapse = ","), ")", sep = "")
  
  paired.test.list <- lapply(seq_len(nrow(paired.test)), function(i) paired.test[i,])
  matching.result <- paired.test.list %>% 
    map(~mutate(.x, 
                matching.optimal = optimal.multi.w(eval(parse(text=(X1.coordinates))), 
                                                   eval(parse(text=(X2.coordinates))), 
                                                   G, mu.hat, covariance.hat, prior.p,
                                                   weight.DS.error = WEIGHT))) %>%
    rlist::list.rbind()
  ##### Matching and predicon test set by Optimal Rule with various weights #####
  matching.result.w <- list()
  for (L in 1:length(weight.DS.error)){
    matching.result.w[[L]] <- paired.test.list %>% 
    map(~mutate(.x, 
                matching.optimal = optimal.multi.w(eval(parse(text=(X1.coordinates))), 
                                                   eval(parse(text=(X2.coordinates))), 
                                                   G, mu.hat, covariance.hat, prior.p,
                                                   weight.DS.error = weight.DS.error[[L]]))) %>%
    rlist::list.rbind()
  }
   
  accuracy.optimal.w <- matching.result.w %>%
    map(~(summarise(.x, 
                    Optimal = mean(.x$matching.optimal == .x$group.matching)))) %>%
    unlist(use.names = FALSE)
  
  sensitivity.optimal.w <- matching.result.w %>%
    map(~(filter(.x, group.matching == 1) %>% 
            summarise(Optimal = mean(matching.optimal == group.matching)))) %>%
    unlist(use.names = FALSE)
  
  specificity.optimal.w <- matching.result.w %>%
    map(~(filter(.x, group.matching == 0) %>% 
            summarise(Optimal = mean(matching.optimal == group.matching)))) %>%
    unlist(use.names = FALSE)

  sens.spec.optimal <- cbind.data.frame(sensitivity.optimal.w, specificity.optimal.w)
  ###############################################################################
 
  return(sens.spec.optimal %>%  
    ggplot(aes(x = 1 - specificity.optimal.w,
               y = sensitivity.optimal.w)) + 
    geom_line(aes(colour = "red"), show.legend = FALSE) + 
    geom_path(data = sens.spec.rf, 
              aes(x = 1 - `roc.rf$specificities`,
                  y = `roc.rf$sensitivities`),
              linetype = 2) +
    xlab("1 - Specificity") + ylab("Sensitivity") +
    ggtitle("Optimal Rule (red) vs. Random Forest"))
}
```

```{r, message = FALSE, echo = FALSE, eval = FALSE, warning = FALSE, fig.align = "center"}
ROC.multi(B = 1, N = 2, G = 2, 
                                    mu.vec.list = list(c(10, -10), c(-1, 1)), 
                                    covariance.matrix.list = lapply(1:2,
                                                                    function(i) matrix(c(100, -25, -25, 100),2,2)), 
                                    prior.p = c(1,1)/2, 
                                    n = 100, n.test = 20,
                                    n.trees = 100) #weight.DS.error = NULL if no weight is used

ROC.multi(B = 1, N = 2, G = 3, 
                                    mu.vec.list = list(c(10, -10), c(-1, 1), c(20, -20)), 
                                    covariance.matrix.list = lapply(1:3,
                                                                    function(i) matrix(c(100, -25, -25, 100),2,2)), 
                                    prior.p = c(1,1,1)/3, 
                                    n = 150, n.test = 30,
                                    n.trees = 100) #weight.DS.error = NULL if no weight is used

ROC.multi(B = 1, N = 2, G = 3, 
                                    mu.vec.list = list(c(1, 10), c(-1, 12), c(0, 10)), 
                                    covariance.matrix.list = lapply(1:3,
                                                                    function(i) matrix(c(1, 0.5, 0.5, 25),2,2)), 
                                    prior.p = c(1,1,1)/3, 
                                    n = 150, n.test = 30,
                                    n.trees = 100)

ROC.multi(B = 1, N = 3, G = 3, 
                                    mu.vec.list = list(c(1, 10, 5), c(-1, 12, 5), c(1, 9, 3)), 
                                    covariance.matrix.list = lapply(1:3,
                                                                    function(i) matrix(c(4, 0.5, -0.3, 
                                                                                         0.5, 25, 0.5, 
                                                                                         -0.3, 0.5, 9),3,3)), 
                                    prior.p = c(1,1,1)/3, 
                                    n = 150, n.test = 30,
                                    n.trees = 100)

ROC.multi(B = 1, N = 2, G = 5, 
                                    mu.vec.list = list(c(1,10), c(-1, 12), c(0, 10), c(2,8), c(-2, 7)), 
                                    covariance.matrix.list = lapply(1:5,
                                                                    function(i) matrix(c(100, -25, -25, 100),2,2)), 
                                    prior.p = c(1,1,1,1,1)/5, 
                                    n = 250, n.test = 50,
                                    n.trees = 100)

#ROC.multi(B = 1, N = 2, G = 10, 
 #                                   mu.vec.list = list(c(1,10), c(-1, 12), c(0, 10), c(2,8), c(-2, 7),
  #                                                     c(-1, -10), c(1, -12), c(0, -10), c(-2, -8), c(2, -7)), 
   #                                 covariance.matrix.list = lapply(1:10,
    #                                                                function(i) matrix(c(100, -25, -25, 100),2,2)), 
     #                               prior.p = rep(0.1, 10), 
      #                              n = 500, n.test = 100,
       #                             n.trees = 100)
###

ROC.multi(B = 1, N = 2, G = 2, 
                                    mu.vec.list = list(c(10, -10), c(-1, 1)), 
                                    covariance.matrix.list = list(matrix(c(100, -25, -25, 100),2,2),
                                                                  matrix(c(64, -25, -25, 64),2,2)), 
                                    prior.p = c(1,1)/2, 
                                    n = 100, n.test = 20,
                                    n.trees = 100) #weight.DS.error = NULL if no weight is used

ROC.multi(B = 1, N = 2, G = 3, 
                                    mu.vec.list = list(c(10, -10), c(-1, 1), c(20, -20)), 
                                    covariance.matrix.list = list(matrix(c(100, -25, -25, 100),2,2),
                                                                  matrix(c(64, -36, -36, 64),2,2),
                                                                  matrix(c(144, -25, -25, 144),2,2)), 
                                    prior.p = c(1,1,1)/3, 
                                    n = 150, n.test = 30,
                                    n.trees = 100) #weight.DS.error = NULL if no weight is used

ROC.multi(B = 1, N = 2, G = 3, 
                                    mu.vec.list = list(c(1, 10), c(-1, 12), c(0, 10)), 
                                    covariance.matrix.list = list(matrix(c(1, 0.5, 0.5, 25),2,2),
                                                                  matrix(c(1, -0.5, -0.5, 25),2,2),
                                                                  matrix(c(2, 0.5, 0.5, 36),2,2)), 
                                    prior.p = c(1,1,1)/3, 
                                    n = 150, n.test = 30,
                                    n.trees = 100)

ROC.multi(B = 1, N = 3, G = 3, 
                                    mu.vec.list = list(c(1, 10, 5), c(-1, 12, 5), c(1, 9, 3)), 
                                    covariance.matrix.list = list(matrix(c(4, 0.5, -0.3, 0.5, 25, 0.5,-0.3, 0.5, 9),3,3),
                                                                  matrix(c(4, 2, -3, 2, 49, 2,-3, 2, 9),3,3),
                                                                  matrix(c(4, 1, -0.3, 1, 36, 1,-0.3, 1, 9),3,3)), 
                                    prior.p = c(1,1,1)/3, 
                                    n = 150, n.test = 30,
                                    n.trees = 100)

ROC.multi(B = 1, N = 2, G = 5, 
                                    mu.vec.list = list(c(1,10), c(-1, 12), c(0, 10), c(2,8), c(-2, 7)), 
                                    covariance.matrix.list = list(matrix(c(100, -25, -25, 100),2,2),
                                                                  matrix(c(100, -25, -25, 64),2,2),
                                                                  matrix(c(64, -25, -25, 36),2,2),
                                                                  matrix(c(16, 25, 25, 81),2,2),
                                                                  matrix(c(100, -64, -64, 100),2,2)), 
                                    prior.p = c(1,1,1,1,1)/5, 
                                    n = 250, n.test = 50,
                                    n.trees = 100)

#ROC.multi(B = 1, N = 2, G = 10, 
 #                                   mu.vec.list = list(c(1,10), c(-1, 12), c(0, 10), c(2,8), c(-2, 7),
  #                                                     c(-1, -10), c(1, -12), c(0, -10), c(-2, -8), c(2, -7)), 
   #                                 covariance.matrix.list = list(matrix(c(100, -25, -25, 100),2,2),
    #                                                              matrix(c(100, -80, -80, 100),2,2),
     #                                                             matrix(c(100, -25, -25, 64),2,2),
      #                                                            matrix(c(100, 50, 50, 64),2,2),
       #                                                           matrix(c(64, -25, -25, 36),2,2),
        #                                                          matrix(c(64, 40, 40, 36),2,2),
         #                                                         matrix(c(16, 25, 25, 81),2,2),
          #                                                        matrix(c(16, -25, -25, 81),2,2),
           #                                                       matrix(c(100, 5, 5, 100),2,2),
            #                                                      matrix(c(100, -64, -64, 100),2,2)), 
             #                       prior.p = rep(0.1, 10), 
              #                      n = 500, n.test = 100,
               #                     n.trees = 100)



```

